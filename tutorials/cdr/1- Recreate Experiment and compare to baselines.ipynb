{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac49a188",
   "metadata": {},
   "source": [
    "To start off, we'll recreate one of the experiments that the Snorkel authors cite and evaluate how well that experiment justifies the use of Snorkel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0d271bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from snorkel import SnorkelSession\n",
    "\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6903fe10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\t8437 candidates\n",
      "Dev set:\t920 candidates\n",
      "Test set:\t4697 candidates\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "ChemicalDisease = candidate_subclass('ChemicalDisease', ['chemical', 'disease'])\n",
    "\n",
    "train = session.query(ChemicalDisease).filter(ChemicalDisease.split == 0).all()\n",
    "dev = session.query(ChemicalDisease).filter(ChemicalDisease.split == 1).all()\n",
    "test = session.query(ChemicalDisease).filter(ChemicalDisease.split == 2).all()\n",
    "\n",
    "print('Training set:\\t{0} candidates'.format(len(train)))\n",
    "print('Dev set:\\t{0} candidates'.format(len(dev)))\n",
    "print('Test set:\\t{0} candidates'.format(len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1201d4de",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-3bfa2a4e1aae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msnorkel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_marginals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_marginals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_marginals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/snorkel-extraction/snorkel/annotations.py\u001b[0m in \u001b[0;36mload_marginals\u001b[0;34m(session, X, split, cids_query, training)\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mcardinality\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCandidate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarginal_tuples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcardinality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m         \u001b[0mmarginals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcids_query\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcardinality\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mcid_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcids_query\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from snorkel.annotations import load_marginals\n",
    "train_marginals = load_marginals(session, split=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9df95883",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_gold_labels\n",
    "L_gold_dev = load_gold_labels(session, annotator_name='gold', split=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26a6231b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LSTM_orig] Training model\n",
      "[LSTM_orig] n_train=3587  #epochs=20  batch size=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cperreault/anaconda3/envs/snorkel-extraction/lib/python3.6/site-packages/torch/nn/functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LSTM_orig] Epoch 1 (16.07s)\tAverage loss=0.688442\tDev F1=51.44\n",
      "[LSTM_orig] Epoch 6 (96.40s)\tAverage loss=0.664749\tDev F1=51.26\n",
      "[LSTM_orig] Epoch 11 (180.14s)\tAverage loss=0.661062\tDev F1=52.00\n",
      "[LSTM_orig] Epoch 16 (265.23s)\tAverage loss=0.658813\tDev F1=52.77\n",
      "[LSTM_orig] Epoch 20 (333.45s)\tAverage loss=0.657877\tDev F1=51.66\n",
      "[LSTM_orig] Model saved as <LSTM_orig>\n",
      "[LSTM_orig] Training done (334.56s)\n",
      "[LSTM_orig] Loaded model <LSTM_orig>\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning.pytorch import LSTM_orig\n",
    "\n",
    "train_kwargs = {\n",
    "    'lr':              0.01,\n",
    "    'embedding_dim':   100,\n",
    "    'hidden_dim':      100,\n",
    "    'n_epochs':        20,\n",
    "    'dropout':         0.5,\n",
    "    'rebalance':       0.25,\n",
    "    'print_freq':      5,\n",
    "}\n",
    "\n",
    "lstm = LSTM_orig(n_threads=None)\n",
    "lstm.train(train, train_marginals, X_dev=dev, Y_dev=L_gold_dev, **train_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63a5eca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnotatorLabels created: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<4697x1 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 4697 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from load_external_annotations import load_external_labels\n",
    "load_external_labels(session, ChemicalDisease, split=2, annotator='gold')\n",
    "L_gold_test = load_gold_labels(session, annotator_name='gold', split=2)\n",
    "L_gold_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f627f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.37417123090227733, 0.85733157199471599, 0.52097130242825618)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.score(test, L_gold_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3eca1500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3236108154140941 1 0.488981824030883\n"
     ]
    }
   ],
   "source": [
    "# find f1 score for a model that predicts \"Yes\" every time\n",
    "tp,fp = 0,0\n",
    "for i in L_gold_test:\n",
    "    if i == 1:\n",
    "        tp += 1\n",
    "    else:\n",
    "        fp += 1\n",
    "precision = tp / (tp + fp)\n",
    "recall = 1\n",
    "f1 = 2/(1/precision + 1/recall)\n",
    "print(precision, recall, f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466ca2fd",
   "metadata": {},
   "source": [
    "Might train this again later and try to get a worse result, but just note that even though the model is better, it's not a significant difference. The \"all yes\" model is also better than the published result. This means that we're not really learning much other than the fact that we should say yes to most results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de8d7de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3236108154140941"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ff7973",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

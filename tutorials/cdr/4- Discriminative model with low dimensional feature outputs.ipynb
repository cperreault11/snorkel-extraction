{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a74deb51",
   "metadata": {},
   "source": [
    "Now, we're going to try to incorporate the additional information in the true dev set labels directly to the final discriminative model using multi-fidelity modeling. For simplicity and interpretability, our end classifier(s) will be simpler than a neural network, but they'll use features from a trained neural network. Because of this, I've modified the neural network architecture to provide an additional layer before class probabilities with 16 nodes. The values that this layer will be used as features of each candidate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617de691",
   "metadata": {},
   "source": [
    "Before going too far: what model do I want to use? GPC doesn't seem to offer many benefits, is there anything else I could use? Why not just use a NN? Might be worth talking to Aidan for this one-- some of the same ideas come into play for the other GP project. Lastly, might be useful to actually read one or two of the papers about MF classification and see what they did, see if I can recreate it ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa8e4a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from snorkel import SnorkelSession\n",
    "\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b8b2cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\t8433 candidates\n",
      "Dev set:\t920 candidates\n",
      "Test set:\t4683 candidates\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "ChemicalDisease = candidate_subclass('ChemicalDisease', ['chemical', 'disease'])\n",
    "\n",
    "train = session.query(ChemicalDisease).filter(ChemicalDisease.split == 0).all()\n",
    "dev = session.query(ChemicalDisease).filter(ChemicalDisease.split == 1).all()\n",
    "test = session.query(ChemicalDisease).filter(ChemicalDisease.split == 2).all()\n",
    "\n",
    "print('Training set:\\t{0} candidates'.format(len(train)))\n",
    "print('Dev set:\\t{0} candidates'.format(len(dev)))\n",
    "print('Test set:\\t{0} candidates'.format(len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "3450587b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_marginals_orig = np.fromfile(\"train_marginals_orig.txt\")\n",
    "train_marginals = train_marginals_orig[:8433].copy()\n",
    "total = train.copy()\n",
    "total.extend(dev.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "870abc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_gold_labels\n",
    "L_gold_dev = load_gold_labels(session, annotator_name='gold', split=1)\n",
    "L_gold_test = load_gold_labels(session, annotator_name='gold', split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c433daff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.learning.pytorch import LSTM # includes an extra layer for smaller set of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cb503c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LSTM] Training model\n",
      "[LSTM] n_train=4112  #epochs=20  batch size=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cperreault/anaconda3/envs/snorkel-extraction/lib/python3.6/site-packages/torch/nn/functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LSTM] Epoch 1 (18.60s)\tAverage loss=0.689290\tDev F1=50.33\n",
      "[LSTM] Epoch 6 (111.65s)\tAverage loss=0.667892\tDev F1=53.23\n",
      "[LSTM] Epoch 11 (206.76s)\tAverage loss=0.664174\tDev F1=52.80\n",
      "[LSTM] Epoch 16 (302.67s)\tAverage loss=0.662036\tDev F1=53.32\n",
      "[LSTM] Epoch 20 (380.19s)\tAverage loss=0.660924\tDev F1=55.15\n",
      "[LSTM] Model saved as <LSTM>\n",
      "[LSTM] Training done (381.27s)\n",
      "[LSTM] Loaded model <LSTM>\n",
      "[LSTM] Model saved as <lstm_with_features>\n"
     ]
    }
   ],
   "source": [
    "train_kwargs = {\n",
    "    'lr':              0.01,\n",
    "    'embedding_dim':   100,\n",
    "    'hidden_dim':      100,\n",
    "    'n_epochs':        20,\n",
    "    'dropout':         0.5,\n",
    "    'rebalance':       0.25,\n",
    "    'print_freq':      5,\n",
    "    'seed':            1701\n",
    "}\n",
    "\n",
    "lstm = LSTM(n_threads=None)\n",
    "lstm.train(total, train_marginals_orig, X_dev=dev, Y_dev=L_gold_dev, **train_kwargs)\n",
    "lstm.save(model_name=\"lstm_with_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e1cdf90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3968514266972778, 0.79920739762219284, 0.53035283804514566)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.score(test,L_gold_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "def27a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_features = lstm.feature_outputs(dev, 100).detach().numpy().reshape(920,10)\n",
    "train_features = lstm.feature_outputs(train, 100).detach().numpy().reshape(8433,10)\n",
    "test_features = lstm.feature_outputs(test, 100).detach().numpy().reshape(4683,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "af87d161",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = train_marginals_orig[:8433].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "61600ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_true = L_gold_dev.toarray().reshape(920,)\n",
    "dev_true[dev_true == -1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e528158a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  1., ...,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6171ddb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7bbbeb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "8a60877d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(10, 50)\n",
    "        self.l2 = nn.Linear(50, 50)\n",
    "        self.l3 = nn.Linear(50,50)\n",
    "        self.l4 = nn.Linear(50,2)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = nn.functional.relu(self.l1(x))\n",
    "        x = nn.functional.relu(self.l2(x))\n",
    "        x = nn.functional.relu(self.l3(x))\n",
    "        x = nn.functional.softmax(self.l4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "5d957697",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_marginals = np.stack([1-train_marginals,train_marginals], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c256e14b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "1a406695",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cperreault/anaconda3/envs/snorkel-extraction/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7223, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(0.7035, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(0.7031, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(0.7029, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(0.7026, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(0.7023, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(0.7020, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(0.7017, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(0.7013, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(0.7011, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "model = SimpleNet()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = Adam(model.parameters(),lr = 0.001)\n",
    "\n",
    "for i in range(500):\n",
    "    model.zero_grad()\n",
    "    output = model(torch.from_numpy(train_features))\n",
    "    loss = criterion(output,torch.from_numpy(train_marginals).type(torch.float))\n",
    "    loss.backward()\n",
    "    if i % 50 == 0:\n",
    "        print(loss)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "4b1ab7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cperreault/anaconda3/envs/snorkel-extraction/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "probs = model(torch.from_numpy(test_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "6bff7c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = probs.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "db182a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.36597148,  0.63402838], dtype=float32)"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "4b4eb212",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cperreault/anaconda3/envs/snorkel-extraction/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "devmodel = SimpleNet()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(devmodel.parameters(),lr = 0.001)\n",
    "\n",
    "for i in range(50):\n",
    "    devmodel.zero_grad()\n",
    "    output = devmodel(torch.from_numpy(dev_features))\n",
    "    loss = criterion(output,torch.from_numpy(dev_true).type(torch.long))\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "b8c80cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cperreault/anaconda3/envs/snorkel-extraction/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "probsdev = devmodel(torch.from_numpy(test_features)).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "acca817e",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "res = L_gold_test.toarray()\n",
    "tp,tn,fp,fn = 0,0,0,0\n",
    "for i in range(len(probsdev)):\n",
    "    pred = 0\n",
    "    dc = max(probsdev[i])\n",
    "    tc = max(probs[i])\n",
    "    if dc > tc:\n",
    "        c += 1\n",
    "        if probsdev[i][0] > 0.5:\n",
    "            pred = 0\n",
    "        else:\n",
    "            pred = 1\n",
    "    else:\n",
    "        if probs[i][0] > .5:\n",
    "            pred = 0\n",
    "        else:\n",
    "            pred = 1\n",
    "    if res[i][0] == 1:\n",
    "        if pred == 1:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "    else:\n",
    "        if pred == 1:\n",
    "            fp += 1\n",
    "        else:\n",
    "            tn += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "ecf7c746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1225 1954 1215 289\n"
     ]
    }
   ],
   "source": [
    "print (tp,fp,tn,fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "f3ea893a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prec = tp / (tp + fp)\n",
    "rec = tp / (tp + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "6752ffbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5220541231621564"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2/(1/prec + 1/rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "2a3aadae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5210335255178304\n"
     ]
    }
   ],
   "source": [
    "print ((tp + tn)/(tp+tn+fp+fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "e8db06e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2652"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "32988a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "ad5b2a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cperreault/anaconda3/envs/snorkel-extraction/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/cperreault/anaconda3/envs/snorkel-extraction/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_model = LogisticRegression()\n",
    "train_model = LogisticRegression()\n",
    "dev_model.fit(dev_features, dev_true)\n",
    "train_model.fit(train_features, train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "0b5d51ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "probsdev = dev_model.predict_proba(test_features)\n",
    "probstrain = train_model.predict_proba(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "8a9c3758",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = L_gold_test.toarray()\n",
    "tp,tn,fp,fn = 0,0,0,0\n",
    "for i in range(len(probsdev)):\n",
    "    pred = 0\n",
    "    if max(probsdev[i]) > max(probstrain[i]):\n",
    "        if probstrain[i][0] > .5:\n",
    "            pred = 0\n",
    "        else:\n",
    "            pred = 1\n",
    "    else:\n",
    "        if probstrain[i][0] > .5:\n",
    "            pred = 0\n",
    "        else:\n",
    "            pred = 1\n",
    "    if res[i][0] == 1:\n",
    "        if pred == 1:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "    else:\n",
    "        if pred == 1:\n",
    "            fp += 1\n",
    "        else:\n",
    "            tn += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "bfe42e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1030 2295 874 484\n"
     ]
    }
   ],
   "source": [
    "print (tp,fp,tn,fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "1c5c2709",
   "metadata": {},
   "outputs": [],
   "source": [
    "prec = tp / (tp + fp)\n",
    "rec = tp / (tp + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "6875d9ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4257077908658814"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2/(1/prec + 1/rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "ab913180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40657698056801195\n"
     ]
    }
   ],
   "source": [
    "print ((tp + tn)/(tp+tn+fp+fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3d88b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6402435",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

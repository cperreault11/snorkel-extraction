{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chemical-Disease Relation (CDR) Tutorial\n",
    "\n",
    "In this example, we'll be writing an application to extract *mentions of* **chemical-induced-disease relationships** from Pubmed abstracts, as per the [BioCreative CDR Challenge](http://www.biocreative.org/resources/corpora/biocreative-v-cdr-corpus/).  This tutorial will show off some of the more advanced features of Snorkel, so we'll assume you've followed the Intro tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by reloading from the last notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from snorkel import SnorkelSession\n",
    "\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\t8433 candidates\n",
      "Dev set:\t920 candidates\n",
      "Test set:\t4683 candidates\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "ChemicalDisease = candidate_subclass('ChemicalDisease', ['chemical', 'disease'])\n",
    "\n",
    "train = session.query(ChemicalDisease).filter(ChemicalDisease.split == 0).all()\n",
    "dev = session.query(ChemicalDisease).filter(ChemicalDisease.split == 1).all()\n",
    "test = session.query(ChemicalDisease).filter(ChemicalDisease.split == 2).all()\n",
    "\n",
    "print('Training set:\\t{0} candidates'.format(len(train)))\n",
    "print('Dev set:\\t{0} candidates'.format(len(dev)))\n",
    "print('Test set:\\t{0} candidates'.format(len(test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part V: Training an LSTM extraction model\n",
    "\n",
    "In the intro tutorial, we automatically featurized the candidates and trained a linear model over these features. Here, we'll train a more complicated model for relation extraction: an LSTM network. You can read more about LSTMs [here](https://en.wikipedia.org/wiki/Long_short-term_memory) or [here](http://colah.github.io/posts/2015-08-Understanding-LSTMs/). An LSTM is a type of recurrent neural network and automatically generates a numerical representation for the candidate based on the sentence text, so no need for featurizing explicitly as in the intro tutorial. LSTMs take longer to train, and Snorkel doesn't currently support hyperparameter searches for them. We'll train a single model here, but feel free to try out other parameter sets. Just make sure to use the development set - and not the test set - for model selection.\n",
    "\n",
    "**Note: Again, training for more epochs than below will greatly improve performance- try it out!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_marginals\n",
    "train_marginals = load_marginals(session, split=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8433,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_marginals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_gold_labels\n",
    "L_gold_dev = load_gold_labels(session, annotator_name='gold', split=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8433,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_marginals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LSTM_orig] Training model\n",
      "[LSTM_orig] n_train=3587  #epochs=20  batch size=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cperreault/anaconda3/envs/snorkel-extraction/lib/python3.6/site-packages/torch/nn/functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LSTM_orig] Epoch 1 (35.79s)\tAverage loss=0.688360\tDev F1=49.95\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d1f6718690b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mlstm2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM_orig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mlstm2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_marginals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_dev\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_dev\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mL_gold_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrain_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/snorkel-extraction/snorkel/learning/pytorch/rnn/rnn_base.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X_train, Y_train, X_dev, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;31m# Note we pass word_dict through here so it gets saved...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         super(RNNBase, self).train(X_train, Y_train, X_dev=X_dev,\n\u001b[0;32m--> 108\u001b[0;31m             word_dict=self.word_dict, **kwargs)\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/snorkel-extraction/snorkel/learning/pytorch/noise_aware_model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X_train, Y_train, n_epochs, lr, batch_size, rebalance, X_dev, Y_dev, print_freq, dev_ckpt, dev_ckpt_delay, save_dir, seed, use_cudnn, **kwargs)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m                 \u001b[0;31m#Compute gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m                 \u001b[0mcalculated_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                 \u001b[0;31m#Step on the optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/snorkel-extraction/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/snorkel-extraction/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from snorkel.learning.pytorch import LSTM_orig\n",
    "\n",
    "train_kwargs = {\n",
    "    'lr':              0.01,\n",
    "    'embedding_dim':   100,\n",
    "    'hidden_dim':      100,\n",
    "    'n_epochs':        20,\n",
    "    'dropout':         0.5,\n",
    "    'rebalance':       0.25,\n",
    "    'print_freq':      5,\n",
    "    'seed':            1701\n",
    "}\n",
    "\n",
    "lstm2 = LSTM_orig(n_threads=None)\n",
    "lstm2.train(train, train_marginals, X_dev=dev, Y_dev=L_gold_dev, **train_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring on the test set\n",
    "\n",
    "Finally, we'll evaluate our performance on the blind test set of 500 documents. We'll load labels similar to how we did for the development set, and use the `score` function of our extraction model to see how we did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnotatorLabels created: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<4683x1 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 4683 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from load_external_annotations import load_external_labels\n",
    "load_external_labels(session, ChemicalDisease, split=2, annotator='gold')\n",
    "L_gold_test = load_gold_labels(session, annotator_name='gold', split=2)\n",
    "L_gold_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.37826086956521737, 0.8619550858652576, 0.52578565672844468)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.score(test, L_gold_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand = np.loadtxt('handlabeled_predictions.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = lstm.marginals(test)\n",
    "pred = np.zeros(out.shape)\n",
    "pred[out >=.5] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for e,x in enumerate(pred):\n",
    "    if x != hand[e]:\n",
    "        c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2483"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4683"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = L_gold_test.toarray().reshape(4683,)\n",
    "handTrue = np.loadtxt('test.txt')\n",
    "true[true == -1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e,x in enumerate(true):\n",
    "    if x != handTrue[e]:\n",
    "        print(e,\"no match\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  0., ...,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handTrue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LSTM] Model saved as <weak_supervision>\n"
     ]
    }
   ],
   "source": [
    "lstm.save(model_name='weak_supervision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = lstm.feature_outputs(test,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([46830])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.reshape(4683,10).detach().numpy()\n",
    "cov = np.matmul(features.transpose(),features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.03753358,  0.2017083 ,  0.29510844,  0.37143236,  0.09484822,\n",
       "          0.25345919, -0.10347617,  0.08641696, -0.78299898,  0.16838549],\n",
       "        [-0.0072735 , -0.37860715,  0.31895134,  0.30586937,  0.01223327,\n",
       "          0.24773405,  0.74877024, -0.07050744,  0.11132964, -0.14755824],\n",
       "        [-0.97038037,  0.0160363 , -0.01084041, -0.01285646, -0.04549643,\n",
       "         -0.07253069, -0.00197182,  0.03527078, -0.0316091 , -0.21964598],\n",
       "        [-0.02340209,  0.3760922 ,  0.72985381, -0.44445309,  0.29165339,\n",
       "         -0.04730985,  0.05445272,  0.00917324,  0.18686424,  0.05014446],\n",
       "        [ 0.0331578 , -0.33265111,  0.18049695, -0.10193478,  0.00814971,\n",
       "         -0.42463708, -0.11076105, -0.74365056, -0.29540676, -0.11109271],\n",
       "        [-0.02671201, -0.22555141, -0.0285029 ,  0.33878416,  0.72534454,\n",
       "         -0.4553903 , -0.06846263,  0.26920882,  0.09669558,  0.11318279],\n",
       "        [ 0.21310924, -0.03591174,  0.01963841, -0.12391026,  0.12060343,\n",
       "          0.01353883, -0.10124086,  0.2694273 , -0.20103449, -0.89418751],\n",
       "        [-0.02270842, -0.64274156,  0.37767747, -0.14553419, -0.3151958 ,\n",
       "          0.02346852, -0.35876805,  0.40685478,  0.00676455,  0.16839495],\n",
       "        [-0.00339779,  0.09926988,  0.24972084,  0.54734856, -0.02949715,\n",
       "          0.25115317, -0.49522546, -0.27667388,  0.4483873 , -0.20343825],\n",
       "        [-0.09271967, -0.29745048, -0.19899483, -0.33089015,  0.51260877,\n",
       "          0.64449859, -0.15652223, -0.21464574, -0.02177085,  0.06816819]], dtype=float32),\n",
       " array([  6.87535234e+04,   1.12277185e+03,   6.08992249e+02,\n",
       "          3.55851868e+02,   2.55197266e+02,   2.04679047e+02,\n",
       "          1.96448364e+02,   1.25019325e+02,   8.67548141e+01,\n",
       "          6.73353271e+01], dtype=float32),\n",
       " array([[-0.03753358, -0.0072735 , -0.97038037, -0.02340209,  0.0331578 ,\n",
       "         -0.02671201,  0.21310924, -0.02270842, -0.00339779, -0.09271967],\n",
       "        [ 0.2017083 , -0.37860715,  0.0160363 ,  0.3760922 , -0.33265111,\n",
       "         -0.22555141, -0.03591174, -0.64274156,  0.09926988, -0.29745048],\n",
       "        [ 0.29510844,  0.31895134, -0.01084041,  0.72985381,  0.18049695,\n",
       "         -0.0285029 ,  0.01963841,  0.37767747,  0.24972084, -0.19899483],\n",
       "        [ 0.37143236,  0.30586937, -0.01285646, -0.44445309, -0.10193478,\n",
       "          0.33878416, -0.12391026, -0.14553419,  0.54734856, -0.33089015],\n",
       "        [ 0.09484822,  0.01223327, -0.04549643,  0.29165339,  0.00814971,\n",
       "          0.72534454,  0.12060343, -0.3151958 , -0.02949715,  0.51260877],\n",
       "        [ 0.25345919,  0.24773405, -0.07253069, -0.04730985, -0.42463708,\n",
       "         -0.4553903 ,  0.01353883,  0.02346852,  0.25115317,  0.64449859],\n",
       "        [-0.10347617,  0.74877024, -0.00197182,  0.05445272, -0.11076105,\n",
       "         -0.06846263, -0.10124086, -0.35876805, -0.49522546, -0.15652223],\n",
       "        [ 0.08641696, -0.07050744,  0.03527078,  0.00917324, -0.74365056,\n",
       "          0.26920882,  0.2694273 ,  0.40685478, -0.27667388, -0.21464574],\n",
       "        [-0.78299898,  0.11132964, -0.0316091 ,  0.18686424, -0.29540676,\n",
       "          0.09669558, -0.20103449,  0.00676455,  0.4483873 , -0.02177085],\n",
       "        [ 0.16838549, -0.14755824, -0.21964598,  0.05014446, -0.11109271,\n",
       "          0.11318279, -0.89418751,  0.16839495, -0.20343825,  0.06816819]], dtype=float32))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.svd(cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
